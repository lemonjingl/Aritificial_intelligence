{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51c1654e",
   "metadata": {},
   "source": [
    "自然语言处理究竟要做一件什么事呢？\n",
    "- 大家可能经常听到分类，机器翻译，情感分析，智能客服，摘要与阅读理解等\n",
    "- 想一想我们在长大的过程中，如何来学习语文的呢？难道只是上课背考试题吗？\n",
    "- 我们语言能力的学习源于生活中的点点滴滴，一次对话，一次阅读都是学习\n",
    "- 那么我们需要训练的NLP模型，只是为了得到最终的一个输出结果吗？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f8d394",
   "metadata": {},
   "source": [
    "如何来培养模型的学习能力？\n",
    "- 需要特定的任务和标签吗？我们的每一次对话难道都对应了标准答案吗？不是的\n",
    "- 更重要的是训练阅读能力，学习能力，理解能力，那么只需要给模型阅读资料即可\n",
    "- 所谓阅读资料，就是咋们人类的文本数据，小说，新闻，电影等都是可以的\n",
    "- 所以，我们现在需要模型具备的是语言理解能力，而不是分类那种专项技能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17332b78",
   "metadata": {},
   "source": [
    "NLP中的江湖人物\n",
    "- 天下风云出我辈，一入江湖岁月催；谁才是当下的大佬呢？\n",
    "- 早期的NLP比较简单，完全没有训练学习能力，只需完成特定领域的任务即可\n",
    "- 现在的NLP可以简单划分成两大门派：BERT系,GPT系\n",
    "- 难道只有它两？还有很多的，只不过它两比较出名，大部分任务都可以套用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a102a8c",
   "metadata": {},
   "source": [
    "NLP究竟拼的什么\n",
    "- 拼网络结构，损失函数，还是各种训练技巧呢？\n",
    "- 从目前NLP比较核心的模型来看，主要拼的是数据量和参数量\n",
    "- 刷屏的模型的以及比较炫酷的模型都是训练数据和参数量极其恐怖，令人发指\n",
    "- 我们能做的什么呢？咋们也要训练模型吗？我们也必须得用海量得数据吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfe36a0",
   "metadata": {},
   "source": [
    "如何开始NLP呢？\n",
    "- 传统算法意义还大嘛？有必要深入学习吗？\n",
    "- 大家如何看一些公开课或者教材，都是长篇大论，谈古说今\n",
    "- 今天的NLP其实已经不再需要传统方法，一些交给Transformer就足够了\n",
    "- NLP领域这么多算法和模型，咋们要神农尝百草一个个来学习一个个来试验吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48273cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a16a4b80",
   "metadata": {},
   "source": [
    "有请咋们今天的主角\n",
    "- 先说重点的：Huggingface就是集大成者于一身，包括了当下NLP所有核心模型\n",
    "- 对我们来说，调用BERT模型，GPT模型及其训练好的权值参数，只需1行代码\n",
    "- 微调我们自己的任务，只需要处理好咋们的数据，然后继续训练模型即可\n",
    "- 即便你对数学一无所知，即便你对代码稀里糊涂，即便你对数据无从下手"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c6697a",
   "metadata": {},
   "source": [
    "它不仅是一个工具包，更是一个社区，也是NLP大佬们的舞台\n",
    "- 给你1000w你能做出来一个抖音不，相信很多开发大佬都是确定的\n",
    "- 但是运营好，却可能要花掉超过千倍的开发成本，所以它不仅仅是模型\n",
    "- 越来越多的学术大佬通过它来开源模型，来宣传论文以及研究成果\n",
    "- 对我们来说这是一件大喜事，大佬们的东西，咋们可以随时来玩了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32484d",
   "metadata": {},
   "source": [
    "关于它的故事\n",
    "- 据传说，30个兼职的开发与算法工程师就撬动了20亿的市值\n",
    "- 其实这离不开开源的力量，AI领域太需要一个舞台和社区了\n",
    "- 时势造英雄，赶上了Transformer在AI领域爆火，第一个吃螃蟹的人\n",
    "- BERT和GPT席卷NLP，Huggingface坐收渔利，社区驱动技术进步"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b64350",
   "metadata": {},
   "source": [
    "一举两得，分而治之\n",
    "- Ai离不开学术上得驱动也离不开工程化得落地\n",
    "- 搞学术的来为社区提供模型以彰显其在该领域的地位与能力，引用量刷刷的\n",
    "- 搞项目的通过社区提供的预训练模型来完成自己的任务，项目落地效率杠杠的\n",
    "- 那么我们呢，先学后用，站在巨人的肩膀上，算法也要熟悉，模型也要会用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5992393e",
   "metadata": {},
   "source": [
    "那么中国为什么诞生不了Huggingface\n",
    "- 一切都是开源的，其实变现之路很难，不想openai搞付费API接口\n",
    "- 30个兼职初创兴趣爱好走到了一切，咱们这兴趣能低房贷？\n",
    "- MMLAB感觉跟Huggingface很像啊，但别忘了得有商汤的资本维持\n",
    "- Huggingface之路不仅于此，接下来要从黑木崖发兵一同江湖了（CV等领域）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d142e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
