{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset,DataLoader,random_split\n",
    "from torch.optim import Adam\n",
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('./ChnSentiCorp_htl_all.csv')\n",
    "data=data.dropna()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.数据加工（dataset,数据集的划分，dataloader）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 只读取2000条数据\n",
    "        self.data=pd.read_csv('./ChnSentiCorp_htl_all.csv').dropna()[:2000]\n",
    "    def __getitem__(self, index):\n",
    "        return self.data.iloc[index]['review'],self.data.iloc[index]['label']\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset=MyDataset()\n",
    "for i in range(4):\n",
    "    print(my_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集的划分\n",
    "train_dataset,test_dataset=random_split(my_dataset,lengths=[0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "tokenizer=AutoTokenizer.from_pretrained('rbt3')\n",
    "\n",
    "def collate_fn(dataset):\n",
    "    texts,labels=[],[]\n",
    "    for item in dataset:\n",
    "        texts.append(item[0])\n",
    "        labels.append(item[1])\n",
    "    inputs=tokenizer(texts, max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    inputs['labels']=torch.tensor(labels)\n",
    "    return inputs\n",
    "\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=32,shuffle=True,collate_fn=collate_fn)\n",
    "test_dataloader=DataLoader(test_dataset,batch_size=64,shuffle=False,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.模型创建与优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AutoModelForSequenceClassification.from_pretrained('rbt3')\n",
    "optim=Adam(model.parameters(),lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in range(2):\n",
    "    for batch in train_dataloader:\n",
    "        batch={k:v for k,v in batch.items()}\n",
    "        optim.zero_grad()\n",
    "        output=model(**batch)\n",
    "        output.loss.backward()\n",
    "        optim.step()\n",
    "    print(f\"ep: {ep}, loss: {output.loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    acc_num=0\n",
    "    for batch in test_dataloader:\n",
    "        inputs={k:v for k,v in batch.items()}\n",
    "        pre=torch.argmax(model(**inputs).logits,dim=-1)\n",
    "        acc_num+=(pre==batch['labels']).float().sum()\n",
    "    acc=acc_num/len(test_dataloader)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen='我觉得这家酒店不错，饭很好吃'\n",
    "id2_label={1:'好评',0:'差评'}\n",
    "\n",
    "with torch.inference_mode():\n",
    "    input=tokenizer(sen,max_length=128,padding='max_length',truncation=True,return_tensors='pt')\n",
    "    input={k:v for k,v in input.items()}\n",
    "    result=torch.argmax(model(**input).logits)\n",
    "    print(id2_label.get(result.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用pipeline预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model.config.id2label=id2_label\n",
    "pipe=pipeline('text-classification',model=model,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "246.396px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
